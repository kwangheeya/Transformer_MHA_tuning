# Transformer_MHA_tuning

## Based on OPENNMT
*  https://github.com/OpenNMT/OpenNMT-py


## Only multi_headed_attn.py file is modified

## Reference code
* http://nlp.seas.harvard.edu/2018/04/03/attention.html

## Data reference
* WMTâ€™14 English-German dataset from https://nlp.stanford.edu/projects/nmt/

